{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee85bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d6879",
   "metadata": {},
   "source": [
    "### facebox function dectect the face frame , extract the boundary points and create the boundary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df6f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facebox(face_net,frame):\n",
    "    \n",
    "    # height \n",
    "    fh = frame.shape[0]\n",
    "   \n",
    "    # width\n",
    "    fw = frame.shape[1]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame,1.0,(300,300),[104,117,123],swapRB=False)\n",
    "    face_net.setInput(blob)\n",
    "    detection = face_net.forward()\n",
    "\n",
    "    points = []\n",
    "\n",
    "    for i in range(detection.shape[2]):\n",
    "        con = detection[0, 0, i, 2]\n",
    "        if con > 0.7:\n",
    "            x1 = int(detection[0,0,i,3] * fw)\n",
    "            y1 = int(detection[0,0,i,4] * fh)\n",
    "            x2 = int(detection[0,0,i,5] * fw)\n",
    "            y2 = int(detection[0,0,i,6] * fh)\n",
    "\n",
    "            points.append([x1,y1,x2,y2])\n",
    "\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),1)\n",
    "\n",
    "\n",
    "    return frame, points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b809f5",
   "metadata": {},
   "source": [
    "## Load opencv detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9cd968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_proto = \"opencv_face_detector.pbtxt\"\n",
    "face_model = \"opencv_face_detector_uint8.pb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212daa15",
   "metadata": {},
   "source": [
    "## Load age model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39a3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_proto = \"age_deploy.prototxt\"\n",
    "age_model = \"age_net.caffemodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e76f44",
   "metadata": {},
   "source": [
    "## Load gender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e8b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_proto = \"gender_deploy.prototxt\"\n",
    "gender_model = \"gender_net.caffemodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe28d667",
   "metadata": {},
   "source": [
    "# read and match the face , age ,and gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a85a6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the face\n",
    "face_net = cv2.dnn.readNet(face_model,face_proto)\n",
    "\n",
    "# read th age\n",
    "age_net = cv2.dnn.readNet(age_model,age_proto)\n",
    "\n",
    "# read the gender\n",
    "gender_net = cv2.dnn.readNet(gender_model,gender_proto)\n",
    "\n",
    "# age classes\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "\n",
    "# gender class\n",
    "genders = [\"Male\",\"Female\"]\n",
    "\n",
    "# Means\n",
    "mean_values = (78.4263377603, 87.7689143744, 114.895847746)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea1712cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"test.mp4\")\n",
    "bold_line = 20\n",
    "while True:    \n",
    "    ret,frame = video.read()\n",
    "    try:\n",
    "        frame,points = facebox(face_net,frame)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # frame = cv2.flip(frame,1)\n",
    "    for i in points:\n",
    "        \n",
    "        try:\n",
    "            face = frame[max(0,i[1]-bold_line):min(i[3]+bold_line,frame.shape[0]-1),max(0,i[0]-bold_line):min(i[2]+bold_line, frame.shape[1]-1)]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        blob = cv2.dnn.blobFromImage(face,1.0,(227,227),mean_values,swapRB=False)\n",
    "\n",
    "        gender_net.setInput(blob)\n",
    "        gender_pred = gender_net.forward()\n",
    "        gender = genders[gender_pred[0].argmax()]\n",
    "\n",
    "        age_net.setInput(blob)\n",
    "        age_pred = age_net.forward()\n",
    "        age = ageList[age_pred[0].argmax()]\n",
    "\n",
    "        label = f\"{gender} {age}\"\n",
    "        cv2.rectangle(frame, (i[0], i[1] - 30), (i[2], i[1]), (0, 255, 0), -1)\n",
    "\n",
    "        cv2.putText(frame, label, (i[0], i[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Window\",frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
